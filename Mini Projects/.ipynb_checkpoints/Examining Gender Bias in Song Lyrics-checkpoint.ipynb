{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Gender Bias in Song Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we aim to compare the gender bias in Hip-Hop songs versus Electronic songs by using Word2Vec to calculate the distances between a selection of words in the lyrics and mean gender embeddings. \n",
    "\n",
    "Datasets used in this mini project:\n",
    "- word_cats.csv: lists of words within certain categories such as occupation.\n",
    "- english_cleaned_lyrics.csv: dataset of song lyrics of 160.856 songs. Retrieved from:\n",
    "https://github.com/hiteshyalamanchili/SongGenreClassification/tree/master/dataset\n",
    "- male_words.p: list of male words.\n",
    "- female_words.p: list of female words.\n",
    "    \n",
    "This project was initially a school assignment for my Master's degree at Utrecht University. Hence, some of the code used in this notebook was adjusted from the code used in this lab manual: https://jveerbeek.gitlab.io/dm-manual/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I import the necessary data. Next, I import the dataset containing the song lyrics. This dataset can then be used to analyze gender bias in the lyrics. I also import word_cats.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DF = 'english_cleaned_lyrics.csv'\n",
    "PATH_CORRECTION = 'indx2newdate.p'\n",
    "\n",
    "def load_dataset(data_path, path_correction):\n",
    "    df = pd.read_csv(data_path)\n",
    "    indx2newdate = pickle.load(open(PATH_CORRECTION, 'rb'))\n",
    "    df['year'] = df['index'].apply(lambda x: int(indx2newdate[x][0][:4]) if indx2newdate [x][0] != \"\" else 0)\n",
    "    return df[df.year > 1960][['song', 'year', 'artist', 'genre', 'lyrics']]\n",
    "\n",
    "df_songs = load_dataset(PATH_DF , PATH_CORRECTION)\n",
    "\n",
    "df_wordcats = pd.read_csv('word_cats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre: Hip-Hop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a subset of all the Hip-Hop songs and I lemmatize them using Spacy so they can be used to train the word embeddings model. Next, I set the parameters of the word embeddings model and train it on the lemmatized songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing the Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_h = df_songs[df_songs.genre == 'Hip-Hop'].lyrics\n",
    "texts_h = [text.lower() for text in texts_h]\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "processed_texts_h = [text for text in nlp.pipe(texts_h,\n",
    "                                               disable=[\"ner\",\n",
    "                                                        \"parser\"])]\n",
    "lemmatized_texts_h = [[token.lemma_ for token in text if not token.is_punct] for text in processed_texts_h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25507600, 38820875)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Word2Vec(size=100,\n",
    "                  sg=1,\n",
    "                  window=10, \n",
    "                  min_count=1,\n",
    "                  workers=1)\n",
    "\n",
    "model1.build_vocab(lemmatized_texts_h)\n",
    "\n",
    "model1.train(lemmatized_texts_h,\n",
    "             total_examples=model1.corpus_count,\n",
    "             epochs=model1.epochs) # grab some coffee while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gender Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I import the male and female words and calculate their mean embedding. Subsequently, I loop over all the categories and all the words in the categories of the word_cats dataset. Next, I calculate the gender biases per word and then calculate their averages over the categories, I store the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = pickle.load(open('male_words.p', 'rb'))\n",
    "words = [word for word in male_words if word in model1.wv.vocab]\n",
    "mean_embedding_male_h = np.mean([model1.wv[word] for word in words], axis=0)\n",
    "\n",
    "female_words = pickle.load(open('female_words.p', 'rb'))\n",
    "words = [word for word in female_words if word in model1.wv.vocab]\n",
    "mean_embedding_female_h = np.mean([model1.wv[word] for word in words], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wouter\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Wouter\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "cat_bias = []\n",
    "for category in df_wordcats.columns:\n",
    "    word_bias = []\n",
    "    for word in df_wordcats[category]:\n",
    "        if word in model1.wv.vocab:\n",
    "            male_dist = np.linalg.norm(np.subtract(model1.wv[word], mean_embedding_male_h))\n",
    "            female_dist = np.linalg.norm(np.subtract(model1.wv[word], mean_embedding_female_h))\n",
    "            bias = male_dist - female_dist\n",
    "            word_bias.append(bias)\n",
    "    cat_bias.append(\n",
    "        {\n",
    "            'Category': category,\n",
    "            'Bias Hip-Hop': np.mean(word_bias),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "df_bias_h = pd.DataFrame(cat_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre: Electronic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same steps are repeated for the genre 'Electronic'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing the songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_e = df_songs[df_songs.genre == 'Electronic'].lyrics\n",
    "texts_e = [text.lower() for text in texts_e]\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "processed_texts_e = [text for text in nlp.pipe(texts_e,\n",
    "                                               disable=[\"ner\",\n",
    "                                                        \"parser\"])]\n",
    "lemmatized_texts_e = [[token.lemma_ for token in text if not token.is_punct] for text in processed_texts_e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3451514, 5555110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Word2Vec(size=100,\n",
    "                  sg=1,\n",
    "                  window=10, \n",
    "                  min_count=1,\n",
    "                  workers=1)\n",
    "\n",
    "model2.build_vocab(lemmatized_texts_e)\n",
    "\n",
    "model2.train(lemmatized_texts_e,\n",
    "             total_examples=model2.corpus_count,\n",
    "             epochs=model2.epochs) # grab some coffee while training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gender Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = pickle.load(open('male_words.p', 'rb'))\n",
    "words = [word for word in male_words if word in model2.wv.vocab]\n",
    "mean_embedding_male_e = np.mean([model2.wv[word] for word in words], axis=0)\n",
    "\n",
    "female_words = pickle.load(open('female_words.p', 'rb'))\n",
    "words = [word for word in female_words if word in model2.wv.vocab]\n",
    "mean_embedding_female_e = np.mean([model2.wv[word] for word in words], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_bias = []\n",
    "for category in df_wordcats.columns:\n",
    "    word_bias = []\n",
    "    for word in df_wordcats[category]:\n",
    "        if word in model2.wv.vocab:\n",
    "            male_dist = np.linalg.norm(np.subtract(model2.wv[word], mean_embedding_male_e))\n",
    "            female_dist = np.linalg.norm(np.subtract(model2.wv[word], mean_embedding_female_e))\n",
    "            bias = male_dist - female_dist\n",
    "            word_bias.append(bias)\n",
    "    cat_bias.append(\n",
    "        {\n",
    "            'Category': category,\n",
    "            'Bias Electronic': np.mean(word_bias),\n",
    "        }\n",
    "    )\n",
    "    avg_bias.append(np.mean(word_bias))\n",
    "    \n",
    "df_bias_e = pd.DataFrame(cat_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Country and Hip-Hop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I combine the bias per category results of both genres in a dataframe for convenient comparison. I also calculate the mean gender bias for each genre. Furthermore, I print the combined dataframes excluding one of 'Category' columns twice, once sorted by Hip-Hop bias and once sorted by Electronic bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022187198570463806\n",
      "0.018668477369758945\n"
     ]
    }
   ],
   "source": [
    "combined_bias = pd.concat([df_bias_h, df_bias_e],axis=1)\n",
    "print(combined_bias['Bias Hip-Hop'].mean())\n",
    "print(combined_bias['Bias Electronic'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Bias Hip-Hop</th>\n",
       "      <th>Bias Electronic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>work</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>-0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>money</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.007808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>leisure</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>0.004449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>occupation</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>-0.022288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>body</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.019641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>relig</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.024891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>family</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negemo</td>\n",
       "      <td>0.025807</td>\n",
       "      <td>0.037792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>percept</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>0.036827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.015025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.043872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>affect</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.037482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>posemo</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>0.036990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  Bias Hip-Hop  Bias Electronic\n",
       "9         work      0.000523        -0.003390\n",
       "11       money      0.008971         0.007808\n",
       "10     leisure      0.010284         0.004449\n",
       "13  occupation      0.010680        -0.022288\n",
       "8         body      0.021640         0.019641\n",
       "12       relig      0.022707         0.024891\n",
       "5       family      0.023280         0.003592\n",
       "3       negemo      0.025807         0.037792\n",
       "7      percept      0.026788         0.036827\n",
       "4       social      0.031037         0.015025\n",
       "6      cogproc      0.032024         0.043872\n",
       "1       affect      0.032931         0.037482\n",
       "2       posemo      0.041764         0.036990\n",
       "0   Unnamed: 0           NaN              NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_bias.iloc[:,[0,1,3]].sort_values('Bias Hip-Hop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Bias Hip-Hop</th>\n",
       "      <th>Bias Electronic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>occupation</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>-0.022288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>work</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>-0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>family</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>leisure</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>0.004449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>money</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.007808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.015025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>body</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.019641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>relig</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.024891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>percept</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>0.036827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>posemo</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>0.036990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>affect</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>0.037482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negemo</td>\n",
       "      <td>0.025807</td>\n",
       "      <td>0.037792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.043872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  Bias Hip-Hop  Bias Electronic\n",
       "13  occupation      0.010680        -0.022288\n",
       "9         work      0.000523        -0.003390\n",
       "5       family      0.023280         0.003592\n",
       "10     leisure      0.010284         0.004449\n",
       "11       money      0.008971         0.007808\n",
       "4       social      0.031037         0.015025\n",
       "8         body      0.021640         0.019641\n",
       "12       relig      0.022707         0.024891\n",
       "7      percept      0.026788         0.036827\n",
       "2       posemo      0.041764         0.036990\n",
       "1       affect      0.032931         0.037482\n",
       "3       negemo      0.025807         0.037792\n",
       "6      cogproc      0.032024         0.043872\n",
       "0   Unnamed: 0           NaN              NaN"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_bias.iloc[:,[0,1,3]].sort_values('Bias Electronic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the gender bias results from the genres Hip-Hop and Electronic, the results suggest that the difference in overall gender bias is very low (0.022 and 0.019 mean over all categories). Furthermore, the results suggest that gender bias is very similar in terms of how it is distributed over categories. For both genres, all mean gender biases per category are between -0.022 and 0.044, with most categories very slightly biased towards women (mean male distance > mean female distance), however, the numbers are so small that they can be considered negligible. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
